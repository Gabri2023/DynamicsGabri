import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import gymnasium as gym
import gymnasium_robotics
import numpy as np
import torch

from my_environment_pkg.models.sac_agent import SAC
from my_environment_pkg.utils.model_saver import load_agent

from my_environment_pkg.run_environment_2 import MyGymEnv


from gymnasium.envs.registration import register

# Registrazione dell'ambiente personalizzato in Gymnasium
register(
    id='MyGymEnv',  # Identificativo del tuo ambiente
    entry_point='my_environment_pkg.run_environment_2:MyGymEnv'
)

# Set up environment and testing parameters
def main():
    # Environment setup
    env = gym.make('MyGymEnv')
    obs = env.reset()[0]
    state_dim = obs.shape[0]  # → 12
    action_dim = env.action_space.shape[0]  # → 6

    # Device setup
    # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device = "cpu"
    model_path = "checkpoints/sac_her_fetchreach_100.pth"

    # Initialize the SAC agent
    sac = SAC(state_dim, action_dim, device=device)

    # Load the trained model
    sac = load_agent(sac, model_path, device)
    print(f"Loaded model from {model_path}")

    # Testing parameters
    num_episodes = 1000
    episode_length = 50

    for episode in range(num_episodes):
        obs, _ = env.reset()
        episode_reward = 0

        for t in range(episode_length):
            print('è il numero di step', t+1)
            # Prepare state
            state = obs

            # Select action
            action = sac.select_action(state)

            # Step in the environment
            next_obs, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated

            # Update state and reward
            obs = next_obs
            episode_reward += reward

            if done:
                break

        print(f"Episode {episode}, Reward: {episode_reward}")

if __name__ == "__main__":
    main()
